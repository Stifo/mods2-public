{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "together-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import joblib\n",
    "import json\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "\n",
    "from es_pandas import es_pandas\n",
    "from IPython.display import display, HTML\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "from kafka.structs import TopicPartition\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from numpy import hstack\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, QuantileTransformer\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "\n",
    "# GPU settings\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'kafka': {\n",
    "        'bootstrap_servers': {\n",
    "            'in': ['127.0.0.1:9092'],\n",
    "            'out': ['127.0.0.1:9092']\n",
    "        },\n",
    "        'topics': {\n",
    "            'in': 'mods-agg-10m',\n",
    "            'out': 'mods-10m-pred'\n",
    "        }\n",
    "    },\n",
    "#     'model': os.path.join('models', 's24-l6-diff')\n",
    "    'model': os.path.join('models', 'm2-incr-nostl')\n",
    "}\n",
    "\n",
    "\n",
    "def load_model(model_dir) -> (Model, Pipeline, Pipeline, dict):\n",
    "    # load cfg\n",
    "    cfg_file = open(os.path.join(model_dir, 'cfg.json'), 'r')\n",
    "    cfg = json.load(cfg_file)\n",
    "    cfg_file.close()\n",
    "    # load transformation pipelines\n",
    "    transform_pipeline_X = joblib.load(os.path.join(model_dir, 'sklearn_pipeline_X.pkl'))\n",
    "    transform_pipeline_Y = joblib.load(os.path.join(model_dir, 'sklearn_pipeline_Y.pkl'))\n",
    "    # load model\n",
    "    model = tf.keras.models.load_model(os.path.join(model_dir, 'model.h5'))\n",
    "    return {\n",
    "        'model': model,\n",
    "        'transform_pipeline_X': transform_pipeline_X,\n",
    "        'transform_pipeline_Y': transform_pipeline_Y,\n",
    "        'cfg': cfg\n",
    "    }\n",
    "\n",
    "\n",
    "#\n",
    "# computes time window for time t; i.e., <begin, end)\n",
    "#\n",
    "def epoch(t, period):\n",
    "    days = period.days\n",
    "    hours = math.floor(period.seconds / 3600)\n",
    "    minutes = math.floor((period.seconds % 3600) / 60)\n",
    "    seconds = period.seconds % 60\n",
    "    beg = t - datetime.timedelta(\n",
    "        days=t.day % days if days > 0 else 0,\n",
    "        hours=t.hour % hours if hours > 0 else 0,\n",
    "        minutes=t.minute % minutes if minutes > 0 else 0,\n",
    "        seconds=t.second % seconds if seconds > 0 else t.second,\n",
    "        microseconds=t.microsecond\n",
    "    )\n",
    "    end = beg + period\n",
    "    return beg, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorporated-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @giang\n",
    "class GiangTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cfg, epsilon=1):\n",
    "        self.epsilon = epsilon\n",
    "        self.remove_peak = cfg['remove_peak']\n",
    "        self.test_stl = cfg['test_stl']\n",
    "        self.stl_period = cfg['stl_period']\n",
    "        self.isfitted = False\n",
    "    def fit(self, X):\n",
    "        if self.remove_peak:\n",
    "            q_min, q_max = np.percentile(X, [25, 75], axis=0)\n",
    "            iqr = q_max - q_min\n",
    "            self.iqr_min = q_min - 1.5*iqr\n",
    "            self.iqr_max = q_max + 1.5*iqr            \n",
    "        self.isfitted = True\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        if self.test_stl:\n",
    "            for col in range(X_.shape[1]):\n",
    "                res = STL(X_[:,col], period=self.stl_period, robust=True).fit()\n",
    "                X_[:,col] = res.trend + res.seasonal\n",
    "        if not self.isfitted:\n",
    "            self.fit(X_)\n",
    "        if self.remove_peak:\n",
    "            X_ = np.clip(X_, a_min=self.iqr_min, a_max=self.iqr_max)\n",
    "        X_ = np.where(X_ < 0, self.epsilon, X_)\n",
    "        return X_\n",
    "    def inverse_transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-state",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'm2-incr-nostl',\n",
       " 'teacher_forcing': False,\n",
       " 'units': 60,\n",
       " 'droupout_rate': 0.6,\n",
       " 'remove_peak': False,\n",
       " 'differential': False,\n",
       " 'forecast_steps': 1,\n",
       " 'forecast_len': 1,\n",
       " 'test_stl': False,\n",
       " 'stl_period': 24,\n",
       " 'train': {'data_file': 'data/buffer-all-1M.tsv',\n",
       "  'epochs': 100,\n",
       "  'epochs_incremental': 10,\n",
       "  'epochs_patience': 10},\n",
       " 'tsg': {'length': 24, 'sampling_rate': 1, 'stride': 1, 'batch_size': 1},\n",
       " 'data': {'split': 0.8,\n",
       "  'X': ['conn_count_uid_in',\n",
       "   'conn_count_uid_out',\n",
       "   'dns_count_uid_out',\n",
       "   'http_count_uid_in',\n",
       "   'ssl_count_uid_in'],\n",
       "  'Y': ['conn_count_uid_in',\n",
       "   'conn_count_uid_out',\n",
       "   'dns_count_uid_out',\n",
       "   'http_count_uid_in',\n",
       "   'ssl_count_uid_in']}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "mods2_model = load_model(cfg['model'])\n",
    "mods2_model['cfg']['train']['epochs_incremental'] = 10\n",
    "display(mods2_model['cfg'])\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    cfg['kafka']['topics']['in'],\n",
    "    bootstrap_servers=cfg['kafka']['bootstrap_servers']['in'],\n",
    "    value_deserializer=lambda v: json.loads(v.decode('utf-8'))\n",
    ")\n",
    "\n",
    "ep = es_pandas('127.0.0.1:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worst-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.datetime.now()\n",
    "# print('now: %s' % now)\n",
    "\n",
    "# window_size = datetime.timedelta(minutes=10)\n",
    "# print('window_size: %s' % window_size)\n",
    "# window = epoch(now, window_size)\n",
    "# print('window: %s' % str(window))\n",
    "\n",
    "# train_start = window[0] - datetime.timedelta(days=14)\n",
    "# print('train_start: %s' % train_start)\n",
    "\n",
    "# timestamps = {}\n",
    "# for tp in consumer.assignment():\n",
    "#     timestamps[tp] = int(train_start.timestamp())\n",
    "# print('timestamps: %s' % timestamps)\n",
    "\n",
    "# offsets = consumer.offsets_for_times(timestamps)\n",
    "# print('offsets: %s' % offsets)\n",
    "\n",
    "# for tp, offset in offsets.items():\n",
    "#     print('tp: %s' % str(tp))\n",
    "#     print('p: %s' % consumer.position(tp))\n",
    "#     consumer.seek(tp, offset.offset)\n",
    "#     print('p: %s' % consumer.position(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "individual-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiate(df:pd.DataFrame, k) -> pd.DataFrame:\n",
    "    return df[k:]-df[:-k].values\n",
    "\n",
    "def inverse_differentiate(df:pd.DataFrame, seen:pd.DataFrame, k) -> pd.DataFrame:\n",
    "    return seen.values+df\n",
    "\n",
    "def transform(mods2_model:dict, df:pd.DataFrame) -> pd.DataFrame:\n",
    "    isdiff = mods2_model['cfg']['differential']\n",
    "    if isdiff:\n",
    "        forecast_steps = mods2_model['cfg']['forecast_steps']\n",
    "        return differentiate(df, forecast_steps)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def inverse_transform(mods2_model:dict, df:pd.DataFrame, df_orig:pd.DataFrame) -> pd.DataFrame:\n",
    "    isdiff = mods2_model['cfg']['differential']\n",
    "    if isdiff:\n",
    "        sequence_length = mods2_model['cfg']['tsg']['length']\n",
    "        forecast_steps = mods2_model['cfg']['forecast_steps']\n",
    "        prev = df_orig[-1:].values\n",
    "        return df + prev\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def create_tsg(mods2_model, X, Y):\n",
    "    forecast_steps = mods2_model['cfg']['forecast_steps']\n",
    "    args = mods2_model['cfg']['tsg']\n",
    "    if forecast_steps > 1:\n",
    "        return TimeseriesGenerator(\n",
    "            X[:-forecast_steps+1],\n",
    "            Y[forecast_steps-1:],\n",
    "            **args\n",
    "        )\n",
    "    else:\n",
    "        return TimeseriesGenerator(\n",
    "            X,\n",
    "            Y,\n",
    "            **args\n",
    "        )\n",
    "\n",
    "def prepare_data_for_train(\n",
    "    mods2_model:dict,\n",
    "    df:pd.DataFrame\n",
    "):\n",
    "    features_X = mods2_model['cfg']['data']['X']\n",
    "    features_Y = mods2_model['cfg']['data']['Y']\n",
    "    pipeline_X = mods2_model['transform_pipeline_X']\n",
    "    pipeline_Y = mods2_model['transform_pipeline_Y']   \n",
    "    #\n",
    "    X = df[features_X]\n",
    "    X = transform(mods2_model, X)\n",
    "    X = X.values.astype('float32')\n",
    "    X = pipeline_X.fit_transform(X)\n",
    "    Y = df[features_Y]\n",
    "    Y = transform(mods2_model, Y)\n",
    "    Y = Y.values.astype('float32')\n",
    "    Y = pipeline_Y.fit_transform(Y)\n",
    "    #\n",
    "    return X,Y\n",
    "\n",
    "def update_model(mods2_model, data_train):\n",
    "    # TODO:\n",
    "    # 1) clone model\n",
    "    # 2) exec in new thread, while old model keeps running\n",
    "    # 3) update transformers???\n",
    "    #\n",
    "    # Checkpointing and earlystopping\n",
    "    checkpoints = ModelCheckpoint(\n",
    "        os.path.join('./checkpoints/lstm-{epoch:02d}.hdf5'),\n",
    "        monitor='loss',\n",
    "        save_best_only=True,\n",
    "        mode='auto',\n",
    "        verbose=0\n",
    "    )\n",
    "    #\n",
    "    earlystops = EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=25,\n",
    "        verbose=0\n",
    "    )\n",
    "    #\n",
    "    callbacks_list = [checkpoints, earlystops]\n",
    "    #\n",
    "    X,Y = prepare_data_for_train(\n",
    "        mods2_model,\n",
    "        data_train\n",
    "    )\n",
    "    tsg_train = create_tsg(\n",
    "        mods2_model,\n",
    "        X,\n",
    "        Y\n",
    "    )\n",
    "    model = mods2_model['model']\n",
    "    for i in range(mods2_model['cfg']['train']['epochs_incremental']):\n",
    "        print('epoch: %d' % (i+1))\n",
    "        model.fit(\n",
    "            tsg_train,\n",
    "            epochs=1,\n",
    "            shuffle=False,\n",
    "            callbacks=callbacks_list,\n",
    "            batch_size=mods2_model['cfg']['tsg']['batch_size'],\n",
    "            verbose=1\n",
    "        )\n",
    "        model.reset_states()\n",
    "\n",
    "def get_time_step(df):\n",
    "    step = df.index[-1] - df.index[-2]\n",
    "\n",
    "def predict(mods2_model, df):\n",
    "    model = mods2_model['model']\n",
    "    isdiff = mods2_model['cfg']['differential']\n",
    "    forecast_steps = mods2_model['cfg']['forecast_steps']\n",
    "    features_X = mods2_model['cfg']['data']['X']\n",
    "    features_Y = mods2_model['cfg']['data']['Y']\n",
    "    pipeline_X = mods2_model['transform_pipeline_X']\n",
    "    pipeline_Y = mods2_model['transform_pipeline_Y']\n",
    "    #\n",
    "    X = df[features_X]\n",
    "    Y = df[features_Y]\n",
    "#     display('X:')\n",
    "#     display(X)\n",
    "#     display('Y:')\n",
    "#     display(X)\n",
    "    #\n",
    "    Xt = transform(mods2_model, X)\n",
    "    Xt = pipeline_X.transform(Xt.to_numpy())\n",
    "    #\n",
    "    Yp = Y[-1:].copy(deep=True)\n",
    "#     display('Yp:')\n",
    "#     display(Yp)\n",
    "#     time_delta = forecast_steps * (Y.index[-1] - Y.index[-2])\n",
    "    time_delta = pd.Timedelta(minutes=10)\n",
    "    Yp.set_index(Yp.index + time_delta, inplace=True)\n",
    "    #\n",
    "    pred = model.predict(Xt[np.newaxis,:], verbose=1, batch_size=1)\n",
    "    pred = pipeline_Y.inverse_transform(pred)\n",
    "    Yp[:] = pred\n",
    "    Yp = inverse_transform(mods2_model, Yp, Y)\n",
    "    #\n",
    "    return Yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wrong-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tp in consumer.assignment():\n",
    "#     consumer.seek_to_beginning(tp)\n",
    "\n",
    "# features\n",
    "features = list(set(mods2_model['cfg']['data']['X'] + mods2_model['cfg']['data']['Y']))\n",
    "features.sort()\n",
    "\n",
    "is_differential = mods2_model['cfg']['differential']\n",
    "context_length = mods2_model['cfg']['tsg']['length'] + (mods2_model['cfg']['forecast_steps'] if is_differential else 0)\n",
    "\n",
    "# store incomming messages in buffer\n",
    "buffer = pd.DataFrame([], columns=features)\n",
    "stripped_beg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in consumer:\n",
    "    protocol = message.key.decode('ascii')\n",
    "    df = pd.read_json(message.value, orient='index')\n",
    "    df.set_index('ts', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index, unit='ms')\n",
    "    cols = [col for col in df if col in features]\n",
    "    df = df[cols]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    buffer = buffer.combine_first(df)\n",
    "    #\n",
    "    # interpolate nan\n",
    "    # buffer[cols] = buffer[buffer[cols].isnull().any().index.values].interpolate(method='time')\n",
    "    # fill nan with zeroes\n",
    "    buffer[cols] = buffer[buffer[cols].isnull().any().index.values].fillna(0)\n",
    "    #\n",
    "    if not stripped_beg and len(buffer.index) > 1 and buffer.iloc[[0]].isnull().values.any():\n",
    "        buffer = buffer[1:]\n",
    "        stripped_beg = True\n",
    "    if len(buffer.index) >= context_length\\\n",
    "        and (not buffer[-1:].isnull().values.any()):\n",
    "        XY = buffer[-context_length:]\n",
    "        Y = predict(mods2_model, XY)\n",
    "#         display('pred:')\n",
    "#         display(Y)\n",
    "#         Y = Y.tz_localize('Europe/Bratislava')\n",
    "        Y['model'] = mods2_model['cfg']['model_name']\n",
    "        Y.reset_index(level=0, inplace=True)\n",
    "        ep_written = ep.to_es(\n",
    "            Y,\n",
    "            cfg['kafka']['topics']['out'],\n",
    "            use_pandas_json=True,\n",
    "            doc_type='pred',\n",
    "            use_index=False\n",
    "        )\n",
    "        #\n",
    "        buffer_len_h = (buffer.index[-1]-buffer.index[0]).total_seconds()/3600        \n",
    "        if buffer_len_h > 24:\n",
    "            data_train = buffer\n",
    "            buffer = buffer[-context_length+1:] # leave previous context for the next prediction\n",
    "            stripped_beg = False\n",
    "            update_model(mods2_model, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "medical-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.to_csv('buffer-all-1M.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inner-examination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conn_count_uid_in</th>\n",
       "      <th>conn_count_uid_out</th>\n",
       "      <th>dns_count_uid_out</th>\n",
       "      <th>http_count_uid_in</th>\n",
       "      <th>ssl_count_uid_in</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-04 23:10:00</th>\n",
       "      <td>9551.0</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-04 23:20:00</th>\n",
       "      <td>10599.0</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-04 23:30:00</th>\n",
       "      <td>10680.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>855.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     conn_count_uid_in  conn_count_uid_out  dns_count_uid_out  \\\n",
       "ts                                                                              \n",
       "2021-05-04 23:10:00             9551.0              1616.0              315.0   \n",
       "2021-05-04 23:20:00            10599.0              1821.0              151.0   \n",
       "2021-05-04 23:30:00            10680.0              1032.0              280.0   \n",
       "\n",
       "                     http_count_uid_in  ssl_count_uid_in  \n",
       "ts                                                        \n",
       "2021-05-04 23:10:00              435.0             342.0  \n",
       "2021-05-04 23:20:00              433.0             271.0  \n",
       "2021-05-04 23:30:00              422.0             855.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-analysis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
